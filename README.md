## 百度迁徙爬虫

爬取百度迁徙上的数据，支持每日增量爬取以下内容：
- 人口迁出数据（比例）：市级->省级、市级->市级、省级->省级、省级->市级
- 人口迁入数据（比例）：市级->省级、市级->市级、省级->省级、省级->市级
- 人口迁出数据（数值/规模指数）：市级、省级
- 人口迁入数据（数值/规模指数）：市级、省级
- 全国迁出数据（比例）：市级、省级
- 全国迁入数据（比例）：市级、省级
- 城内迁徙数据：市级

### 环境依赖
- requests
- tqdm
- pymongo
- MongoDB数据库
- json

### 使用方法

`location_ids.txt`文件存放了待爬取的省级、市级行政单位的行政区划代码，可根据需要自行修改

出于方便存取的考虑，数据存储使用了MongoDB数据库，需要安装相应的环境才能使用本程序。如有需要请修改`connect_str`为自己的数据库连接URL

执行`main.py`中的`fetch_timerange()`方法，传入格式为`YYYYMMDD`的起止日期即可进行爬取，如`20200402`。若仅需要爬取一天，则设置相同的起止日期

### 数据结构

数据包含三个Collection，分别为全国分布数据（cn_distribution）、省级迁徙数据（province_flow）和市级迁徙数据(city_flow)：
- 全国分布数据（cn_distribution），每日的数据包含4个Document，分别为省级的迁入(move_in)、迁出(move_out)和市级的迁入、迁出情况。每个Document中包含各省或市的具体情况数组。
- 省级迁徙数据（province_flow），每日的数据包含33 * 4个Document，即我国33个省级行政单位（含直辖市及港澳，不含台湾地区）每日的省级迁入、迁出和市级迁入、迁出情况。
- 市级迁徙数据(city_flow)，每日的数据包含368 * 4个Document，即百度迁徙所收录的368个市级行政单位（为方便分析，含直辖市及港澳，不含台湾地区）每日的省级迁入、迁出和市级迁入、迁出情况。

